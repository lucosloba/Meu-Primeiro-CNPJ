from fastapi import FastAPI, Request
from fastapi.responses import PlainTextResponse
from dotenv import load_dotenv
import openai
import os
import re

load_dotenv()

client = openai.OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)

app = FastAPI()
students = {}

@app.get("/health")
def health():
    return {"status": "ok"}

def eh_pergunta(texto: str) -> bool:
    texto = texto.lower().strip()
    return texto.endswith("?") or any(texto.startswith(p) for p in ["qual", "quais", "como", "quando", "o que", "por que"])

def responder_e_avancar(etapa_atual, perfil, resposta_aluno):
    prompts = {
        "perfil_nome": {
            "prompt": (
                "Voc√™ √© um instrutor chamado Pjotinha, respons√°vel pelo curso 'Meu Primeiro CNPJ'. "
                "Voc√™ j√° conhece o aluno e agora quer perguntar o nome dele de forma simp√°tica e clara. "
                "Pe√ßa apenas o nome e n√£o fa√ßa outras perguntas."
            )
        },
        "perfil_curso": {
            "prompt": (
                f"O aluno se chama {perfil['nome']}. Agora pergunte de forma simp√°tica e clara qual curso ou √°rea de forma√ß√£o o aluno est√° cursando atualmente. "
                "Evite perguntar onde estuda ou se est√° interessado. Pergunte apenas o que ele cursa na universidade."
                "Evite falar ol√° novamente pois voc√™ j√° disse na mensagem de apresenta√ß√£o"
            )
        },
        "perfil_semestre": {
            "prompt": (
                f"O aluno cursa {perfil['curso']}. Agora mostre empolga√ß√£o com o curso que o aluno faz e pergunte em qual semestre ele est√°. "
                "Seja direto, simp√°tico e n√£o pergunte mais de uma coisa."
                "Evite falar ol√° novamente pois voc√™ j√° disse na mensagem de apresenta√ß√£o"
            )
        },
        "perfil_interesses": {
            "prompt": (
                f"O aluno est√° no {perfil['semestre']} semestre. Agora pergunte apenas sobre os interesses dele em empreender. "
                "N√£o inclua outras perguntas. Use tom empolgado e pr√≥ximo."
            )
        },
        "pronto": {
            "prompt": (
                f"Voc√™ √© o instrutor Pjotinha. O aluno {perfil['nome']} completou o perfil (curso: {perfil['curso']}, semestre: {perfil['semestre']}, interesses: {perfil['interesses']}). "
                "Agrade√ßa de forma simp√°tica por compartilhar essas informa√ß√µes, diga que foi um prazer conhecer ele melhor e finalize com a pergunta: "
                "'Voc√™ est√° pronto para dar o primeiro passo no mundo do empreendedorismo?' N√£o use a palavra 'perfil'."
            )
        }
    }

    try:
        mensagem = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© o instrutor Pjotinha, simp√°tico, direto e focado no curso de empreendedorismo. Nunca fa√ßa mais de uma pergunta por vez."},
                {"role": "user", "content": prompts[etapa_atual]["prompt"]}
            ],
            temperature=0.7,
            max_tokens=200
        ).choices[0].message.content.strip()
    except Exception as e:
        print(f"Erro ao gerar resposta da etapa {etapa_atual}: {e}")
        mensagem = "Desculpe, houve um erro. Poderia repetir?"

    return mensagem

def extrair_dado(etapa, entrada):
    instrucoes = {
        "perfil_nome": "Extraia apenas o primeiro nome da mensagem abaixo. Responda s√≥ com o nome.",
        "perfil_curso": "Extraia apenas o nome do curso ou √°rea que o aluno est√° cursando na universidade.",
        "perfil_semestre": "Extraia apenas o n√∫mero do semestre da universidade em que o aluno est√°, como 1, 2, 3...",
        "perfil_interesses": "Resuma os interesses empreendedores do aluno com poucas palavras."
    }

    try:
        resultado = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": instrucoes[etapa]},
                {"role": "user", "content": entrada}
            ],
            temperature=0.3,
            max_tokens=30
        )
        return resultado.choices[0].message.content.strip()
    except Exception as e:
        print(f"Erro ao extrair dado de {etapa}: {e}")
        return entrada

@app.post("/webhook", response_class=PlainTextResponse)
async def webhook(request: Request):
    form = await request.form()
    incoming_msg = form.get("Body", "").strip()
    sender = form.get("From", "")

    if not incoming_msg or not sender:
        return "Mensagem inv√°lida."

    if sender not in students:
        students[sender] = {
            "profile": {
                "nome": None,
                "curso": None,
                "semestre": None,
                "interesses": None
            },
            "etapa": "inicio",
            "history": []
        }

    aluno = students[sender]
    etapa = aluno["etapa"]
    perfil = aluno["profile"]

    if etapa == "inicio":
        aluno["etapa"] = "perfil_nome"
        return (
            "Ol√°! üëã Me chamo *Pjotinha*, serei seu instrutor no curso *Meu Primeiro CNPJ*.\n"
            "Posso te conhecer melhor? Como voc√™ se chama?"
        )

    if etapa != "pronto":
        if eh_pergunta(incoming_msg):
            # Ignora coleta e responde como assistente livre
            prompt = f"O aluno fez a seguinte pergunta: {incoming_msg}. Responda como o instrutor Pjotinha, de forma clara e empolgada."
            try:
                resposta = client.chat.completions.create(
                    model="openai/gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "Voc√™ √© o Pjotinha, um instrutor simp√°tico e direto em um curso de empreendedorismo para universit√°rios."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=400
                )
                return resposta.choices[0].message.content.strip()
            except Exception as e:
                print(f"Erro ao responder pergunta do aluno: {e}")
                return "Desculpe, tive um problema ao responder. Pode repetir?"

        valor_extraido = extrair_dado(etapa, incoming_msg)
        campo = etapa.replace("perfil_", "")
        aluno["profile"][campo] = valor_extraido

        etapas = ["perfil_nome", "perfil_curso", "perfil_semestre", "perfil_interesses", "pronto"]
        proxima_etapa = etapas[etapas.index(etapa) + 1]
        aluno["etapa"] = proxima_etapa

        return responder_e_avancar(proxima_etapa, aluno["profile"], incoming_msg)

    prompt = f"""
Voc√™ √© o Pjotinha, assistente virtual do curso de empreendedorismo. O aluno se chama {perfil['nome']}, faz {perfil['curso']}, est√° no {perfil['semestre']} semestre e tem interesse em {perfil['interesses']}.
Responda a seguinte mensagem com base nesse perfil: "{incoming_msg}"
Seja simp√°tico, informativo e direto.
"""

    try:
        resposta = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente educacional especialista em empreendedorismo, chamado Pjotinha."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        reply = resposta.choices[0].message.content.strip()

    except Exception as e:
        print(f"Erro na resposta livre: {e}")
        reply = "Desculpe, tive um problema t√©cnico. Pode perguntar novamente?"

    aluno["history"].append(f"Aluno: {incoming_msg}")
    aluno["history"].append(f"IA: {reply}")
    return reply